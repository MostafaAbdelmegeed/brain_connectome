{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('C:/Users/mosta/OneDrive - UNCG\\Academics/CSC 699 - Thesis/repos/brain_connectome/graphIO')\n",
    "from graphIO import read_ppmi_data\n",
    "from asymmetry import calculate_inter_hemispheric_asymmetry_vector\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPMI_DIR = \"C:/Users/mosta/OneDrive - UNCG/Academics/CSC 699 - Thesis/data/ppmi\"\n",
    "DEVICE = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ATLAS = 116\n",
    "HIDDEN_DIM = 256\n",
    "LATENT_DIM = 100\n",
    "EPOCHS = 100\n",
    "ASYMMETRY_METHOD = 'ai'\n",
    "CCA_COMPONENTS = 2\n",
    "LEARNING_RATE = 0.00001\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing directories: 100%|██████████| 209/209 [00:01<00:00, 126.29it/s]\n"
     ]
    }
   ],
   "source": [
    "ppmi_data = read_ppmi_data(PPMI_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 116, 116) (113, 116, 116) (67, 116, 116) (14, 116, 116)\n"
     ]
    }
   ],
   "source": [
    "control_matrices = np.array([ppmi_data['sub-control'][i] for i in ppmi_data['sub-control']])\n",
    "patient_matrices = np.array([ppmi_data['sub-patient'][i] for i in ppmi_data['sub-patient']])\n",
    "prodromal_matrices = np.array([ppmi_data['sub-prodromal'][i] for i in ppmi_data['sub-prodromal']])\n",
    "swedd_matrices = np.array([ppmi_data['sub-swedd'][i] for i in ppmi_data['sub-swedd']])\n",
    "print(control_matrices.shape, patient_matrices.shape, prodromal_matrices.shape, swedd_matrices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 58) (113, 58) (67, 58) (14, 58)\n"
     ]
    }
   ],
   "source": [
    "control_asymm_vectors = np.array([calculate_inter_hemispheric_asymmetry_vector(matrix, method=ASYMMETRY_METHOD) for matrix in control_matrices])\n",
    "patient_asymm_vectors = np.array([calculate_inter_hemispheric_asymmetry_vector(matrix, method=ASYMMETRY_METHOD) for matrix in patient_matrices])\n",
    "prodromal_asymm_vectors = np.array([calculate_inter_hemispheric_asymmetry_vector(matrix, method=ASYMMETRY_METHOD) for matrix in prodromal_matrices])\n",
    "swedd_asymm_vectors = np.array([calculate_inter_hemispheric_asymmetry_vector(matrix, method=ASYMMETRY_METHOD) for matrix in swedd_matrices])\n",
    "print(control_asymm_vectors.shape, patient_asymm_vectors.shape, prodromal_asymm_vectors.shape, swedd_asymm_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = {}\n",
    "tensors['control'] = torch.tensor(control_asymm_vectors.reshape((-1, 1, ATLAS//2)), dtype=torch.float32).unsqueeze(1)\n",
    "tensors['patient'] = torch.tensor(patient_asymm_vectors.reshape((-1, 1, ATLAS//2)), dtype=torch.float32).unsqueeze(1)\n",
    "tensors['prodromal'] = torch.tensor(prodromal_asymm_vectors.reshape((-1, 1, ATLAS//2)), dtype=torch.float32).unsqueeze(1)\n",
    "tensors['swedd'] = torch.tensor(swedd_asymm_vectors.reshape((-1, 1, ATLAS//2)), dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetryVAE(nn.Module):\n",
    "    def __init__(self, input_shape=(1, 1, ATLAS//2), hidden_dim=HIDDEN_DIM, latent_dim=LATENT_DIM):\n",
    "        super(AsymmetryVAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),  # Assuming a small convolution kernel\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # Calculate the flattened size after convolution\n",
    "        self.flattened_size = 64 * 1 * ATLAS//2\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.flattened_size, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        self.fc4 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc5 = nn.Linear(hidden_dim, self.flattened_size)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(1, (64, 1, ATLAS//2)),\n",
    "            nn.ConvTranspose2d(64, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, 3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        h = torch.relu(self.fc1(h))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = torch.relu(self.fc4(z))\n",
    "        h = torch.relu(self.fc5(h))\n",
    "        h = self.decoder(h)\n",
    "        return h\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    MSE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return MSE + KLD\n",
    "\n",
    "def calculate_mse(dataloader, model):\n",
    "    model.eval()\n",
    "    mse_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in dataloader:\n",
    "            data = data.to(device)\n",
    "            recon, _, _ = model(data)\n",
    "            mse_loss += nn.functional.mse_loss(recon, data, reduction='sum').item()\n",
    "    return mse_loss / len(dataloader.dataset)\n",
    "\n",
    "# Function to get the latent space representation\n",
    "def get_latent_space(model, data_vector, use_mean=True):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # No need to compute gradients\n",
    "        # Ensure the data is in the correct shape and tensor format\n",
    "        data_tensor = torch.tensor(data_vector.reshape(1, 1, 1, ATLAS//2), dtype=torch.float32).to(device)\n",
    "        # Pass through the encoder to get mu and logvar\n",
    "        mu, logvar = model.encode(data_tensor)\n",
    "        if use_mean:\n",
    "            return mu.cpu().numpy()  # Return the mean as the latent representation\n",
    "        else:\n",
    "            # Sample from the distribution using reparameterization trick\n",
    "            z = model.reparameterize(mu, logvar)\n",
    "            return z.cpu().numpy()  # Return the sampled latent representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for group: control\n",
      "Train Epoch: 1 [0/15 (0%)]\tLoss: 13.440023\n",
      "====> Epoch: 1 Average loss: 13.4400\n",
      "====> Validation MSE after Epoch 1: 13.1160\n",
      "Train Epoch: 2 [0/15 (0%)]\tLoss: 13.205457\n",
      "====> Epoch: 2 Average loss: 13.2055\n",
      "====> Validation MSE after Epoch 2: 12.7988\n",
      "Train Epoch: 3 [0/15 (0%)]\tLoss: 12.924191\n",
      "====> Epoch: 3 Average loss: 12.9242\n",
      "====> Validation MSE after Epoch 3: 12.6207\n",
      "Train Epoch: 4 [0/15 (0%)]\tLoss: 12.598563\n",
      "====> Epoch: 4 Average loss: 12.5986\n",
      "====> Validation MSE after Epoch 4: 12.3870\n",
      "Train Epoch: 5 [0/15 (0%)]\tLoss: 12.541660\n",
      "====> Epoch: 5 Average loss: 12.5417\n",
      "====> Validation MSE after Epoch 5: 12.2465\n",
      "Train Epoch: 6 [0/15 (0%)]\tLoss: 12.286804\n",
      "====> Epoch: 6 Average loss: 12.2868\n",
      "====> Validation MSE after Epoch 6: 11.9378\n",
      "Train Epoch: 7 [0/15 (0%)]\tLoss: 12.068985\n",
      "====> Epoch: 7 Average loss: 12.0690\n",
      "====> Validation MSE after Epoch 7: 11.8479\n",
      "Train Epoch: 8 [0/15 (0%)]\tLoss: 11.839353\n",
      "====> Epoch: 8 Average loss: 11.8394\n",
      "====> Validation MSE after Epoch 8: 11.4070\n",
      "Train Epoch: 9 [0/15 (0%)]\tLoss: 11.676620\n",
      "====> Epoch: 9 Average loss: 11.6766\n",
      "====> Validation MSE after Epoch 9: 11.3341\n",
      "Train Epoch: 10 [0/15 (0%)]\tLoss: 11.452952\n",
      "====> Epoch: 10 Average loss: 11.4530\n",
      "====> Validation MSE after Epoch 10: 11.2454\n",
      "Train Epoch: 11 [0/15 (0%)]\tLoss: 11.168774\n",
      "====> Epoch: 11 Average loss: 11.1688\n",
      "====> Validation MSE after Epoch 11: 10.7965\n",
      "Train Epoch: 12 [0/15 (0%)]\tLoss: 11.031395\n",
      "====> Epoch: 12 Average loss: 11.0314\n",
      "====> Validation MSE after Epoch 12: 10.7913\n",
      "Train Epoch: 13 [0/15 (0%)]\tLoss: 10.875495\n",
      "====> Epoch: 13 Average loss: 10.8755\n",
      "====> Validation MSE after Epoch 13: 10.3521\n",
      "Train Epoch: 14 [0/15 (0%)]\tLoss: 10.593748\n",
      "====> Epoch: 14 Average loss: 10.5937\n",
      "====> Validation MSE after Epoch 14: 10.1742\n",
      "Train Epoch: 15 [0/15 (0%)]\tLoss: 10.305276\n",
      "====> Epoch: 15 Average loss: 10.3053\n",
      "====> Validation MSE after Epoch 15: 10.0213\n",
      "Train Epoch: 16 [0/15 (0%)]\tLoss: 10.012327\n",
      "====> Epoch: 16 Average loss: 10.0123\n",
      "====> Validation MSE after Epoch 16: 9.4406\n",
      "Train Epoch: 17 [0/15 (0%)]\tLoss: 9.660926\n",
      "====> Epoch: 17 Average loss: 9.6609\n",
      "====> Validation MSE after Epoch 17: 9.3583\n",
      "Train Epoch: 18 [0/15 (0%)]\tLoss: 9.429701\n",
      "====> Epoch: 18 Average loss: 9.4297\n",
      "====> Validation MSE after Epoch 18: 9.1755\n",
      "Train Epoch: 19 [0/15 (0%)]\tLoss: 9.187974\n",
      "====> Epoch: 19 Average loss: 9.1880\n",
      "====> Validation MSE after Epoch 19: 8.8690\n",
      "Train Epoch: 20 [0/15 (0%)]\tLoss: 9.148309\n",
      "====> Epoch: 20 Average loss: 9.1483\n",
      "====> Validation MSE after Epoch 20: 8.8263\n",
      "Train Epoch: 21 [0/15 (0%)]\tLoss: 8.912324\n",
      "====> Epoch: 21 Average loss: 8.9123\n",
      "====> Validation MSE after Epoch 21: 8.4338\n",
      "Train Epoch: 22 [0/15 (0%)]\tLoss: 8.609685\n",
      "====> Epoch: 22 Average loss: 8.6097\n",
      "====> Validation MSE after Epoch 22: 8.0764\n",
      "Train Epoch: 23 [0/15 (0%)]\tLoss: 8.375647\n",
      "====> Epoch: 23 Average loss: 8.3756\n",
      "====> Validation MSE after Epoch 23: 7.8737\n",
      "Train Epoch: 24 [0/15 (0%)]\tLoss: 8.064401\n",
      "====> Epoch: 24 Average loss: 8.0644\n",
      "====> Validation MSE after Epoch 24: 7.6833\n",
      "Train Epoch: 25 [0/15 (0%)]\tLoss: 7.790329\n",
      "====> Epoch: 25 Average loss: 7.7903\n",
      "====> Validation MSE after Epoch 25: 7.4271\n",
      "Train Epoch: 26 [0/15 (0%)]\tLoss: 7.488003\n",
      "====> Epoch: 26 Average loss: 7.4880\n",
      "====> Validation MSE after Epoch 26: 7.2922\n",
      "Train Epoch: 27 [0/15 (0%)]\tLoss: 7.321833\n",
      "====> Epoch: 27 Average loss: 7.3218\n",
      "====> Validation MSE after Epoch 27: 7.0218\n",
      "Train Epoch: 28 [0/15 (0%)]\tLoss: 7.001456\n",
      "====> Epoch: 28 Average loss: 7.0015\n",
      "====> Validation MSE after Epoch 28: 6.5699\n",
      "Train Epoch: 29 [0/15 (0%)]\tLoss: 6.742811\n",
      "====> Epoch: 29 Average loss: 6.7428\n",
      "====> Validation MSE after Epoch 29: 6.5285\n",
      "Train Epoch: 30 [0/15 (0%)]\tLoss: 6.228277\n",
      "====> Epoch: 30 Average loss: 6.2283\n",
      "====> Validation MSE after Epoch 30: 6.1569\n",
      "Train Epoch: 31 [0/15 (0%)]\tLoss: 5.933356\n",
      "====> Epoch: 31 Average loss: 5.9334\n",
      "====> Validation MSE after Epoch 31: 5.4398\n",
      "Train Epoch: 32 [0/15 (0%)]\tLoss: 5.971711\n",
      "====> Epoch: 32 Average loss: 5.9717\n",
      "====> Validation MSE after Epoch 32: 5.6969\n",
      "Train Epoch: 33 [0/15 (0%)]\tLoss: 5.592354\n",
      "====> Epoch: 33 Average loss: 5.5924\n",
      "====> Validation MSE after Epoch 33: 5.1349\n",
      "Train Epoch: 34 [0/15 (0%)]\tLoss: 5.404784\n",
      "====> Epoch: 34 Average loss: 5.4048\n",
      "====> Validation MSE after Epoch 34: 4.9217\n",
      "Train Epoch: 35 [0/15 (0%)]\tLoss: 4.810751\n",
      "====> Epoch: 35 Average loss: 4.8108\n",
      "====> Validation MSE after Epoch 35: 4.8172\n",
      "Train Epoch: 36 [0/15 (0%)]\tLoss: 4.655558\n",
      "====> Epoch: 36 Average loss: 4.6556\n",
      "====> Validation MSE after Epoch 36: 4.7463\n",
      "Train Epoch: 37 [0/15 (0%)]\tLoss: 4.832200\n",
      "====> Epoch: 37 Average loss: 4.8322\n",
      "====> Validation MSE after Epoch 37: 4.1698\n",
      "Train Epoch: 38 [0/15 (0%)]\tLoss: 4.564555\n",
      "====> Epoch: 38 Average loss: 4.5646\n",
      "====> Validation MSE after Epoch 38: 3.9895\n",
      "Train Epoch: 39 [0/15 (0%)]\tLoss: 3.912867\n",
      "====> Epoch: 39 Average loss: 3.9129\n",
      "====> Validation MSE after Epoch 39: 3.7596\n",
      "Train Epoch: 40 [0/15 (0%)]\tLoss: 4.009055\n",
      "====> Epoch: 40 Average loss: 4.0091\n",
      "====> Validation MSE after Epoch 40: 3.3828\n",
      "Train Epoch: 41 [0/15 (0%)]\tLoss: 3.635934\n",
      "====> Epoch: 41 Average loss: 3.6359\n",
      "====> Validation MSE after Epoch 41: 3.3724\n",
      "Train Epoch: 42 [0/15 (0%)]\tLoss: 3.406829\n",
      "====> Epoch: 42 Average loss: 3.4068\n",
      "====> Validation MSE after Epoch 42: 2.8657\n",
      "Train Epoch: 43 [0/15 (0%)]\tLoss: 3.329355\n",
      "====> Epoch: 43 Average loss: 3.3294\n",
      "====> Validation MSE after Epoch 43: 2.8172\n",
      "Train Epoch: 44 [0/15 (0%)]\tLoss: 2.914625\n",
      "====> Epoch: 44 Average loss: 2.9146\n",
      "====> Validation MSE after Epoch 44: 2.5774\n",
      "Train Epoch: 45 [0/15 (0%)]\tLoss: 2.659524\n",
      "====> Epoch: 45 Average loss: 2.6595\n",
      "====> Validation MSE after Epoch 45: 2.4241\n",
      "Train Epoch: 46 [0/15 (0%)]\tLoss: 2.611058\n",
      "====> Epoch: 46 Average loss: 2.6111\n",
      "====> Validation MSE after Epoch 46: 2.1498\n",
      "Train Epoch: 47 [0/15 (0%)]\tLoss: 2.412040\n",
      "====> Epoch: 47 Average loss: 2.4120\n",
      "====> Validation MSE after Epoch 47: 2.1326\n",
      "Train Epoch: 48 [0/15 (0%)]\tLoss: 2.361258\n",
      "====> Epoch: 48 Average loss: 2.3613\n",
      "====> Validation MSE after Epoch 48: 2.0915\n",
      "Train Epoch: 49 [0/15 (0%)]\tLoss: 2.163987\n",
      "====> Epoch: 49 Average loss: 2.1640\n",
      "====> Validation MSE after Epoch 49: 1.8535\n",
      "Train Epoch: 50 [0/15 (0%)]\tLoss: 2.003125\n",
      "====> Epoch: 50 Average loss: 2.0031\n",
      "====> Validation MSE after Epoch 50: 1.7118\n",
      "Train Epoch: 51 [0/15 (0%)]\tLoss: 1.767892\n",
      "====> Epoch: 51 Average loss: 1.7679\n",
      "====> Validation MSE after Epoch 51: 1.7179\n",
      "Train Epoch: 52 [0/15 (0%)]\tLoss: 1.855889\n",
      "====> Epoch: 52 Average loss: 1.8559\n",
      "====> Validation MSE after Epoch 52: 1.5649\n",
      "Train Epoch: 53 [0/15 (0%)]\tLoss: 1.817782\n",
      "====> Epoch: 53 Average loss: 1.8178\n",
      "====> Validation MSE after Epoch 53: 1.5887\n",
      "Train Epoch: 54 [0/15 (0%)]\tLoss: 1.493113\n",
      "====> Epoch: 54 Average loss: 1.4931\n",
      "====> Validation MSE after Epoch 54: 1.2261\n",
      "Train Epoch: 55 [0/15 (0%)]\tLoss: 1.260333\n",
      "====> Epoch: 55 Average loss: 1.2603\n",
      "====> Validation MSE after Epoch 55: 1.0970\n",
      "Train Epoch: 56 [0/15 (0%)]\tLoss: 1.302363\n",
      "====> Epoch: 56 Average loss: 1.3024\n",
      "====> Validation MSE after Epoch 56: 1.2350\n",
      "Train Epoch: 57 [0/15 (0%)]\tLoss: 1.273059\n",
      "====> Epoch: 57 Average loss: 1.2731\n",
      "====> Validation MSE after Epoch 57: 0.9100\n",
      "Train Epoch: 58 [0/15 (0%)]\tLoss: 0.997045\n",
      "====> Epoch: 58 Average loss: 0.9970\n",
      "====> Validation MSE after Epoch 58: 0.7710\n",
      "Train Epoch: 59 [0/15 (0%)]\tLoss: 0.957206\n",
      "====> Epoch: 59 Average loss: 0.9572\n",
      "====> Validation MSE after Epoch 59: 0.8604\n",
      "Train Epoch: 60 [0/15 (0%)]\tLoss: 0.923065\n",
      "====> Epoch: 60 Average loss: 0.9231\n",
      "====> Validation MSE after Epoch 60: 0.6918\n",
      "Train Epoch: 61 [0/15 (0%)]\tLoss: 0.972353\n",
      "====> Epoch: 61 Average loss: 0.9724\n",
      "====> Validation MSE after Epoch 61: 0.6031\n",
      "Train Epoch: 62 [0/15 (0%)]\tLoss: 0.692914\n",
      "====> Epoch: 62 Average loss: 0.6929\n",
      "====> Validation MSE after Epoch 62: 0.5603\n",
      "Train Epoch: 63 [0/15 (0%)]\tLoss: 0.605612\n",
      "====> Epoch: 63 Average loss: 0.6056\n",
      "====> Validation MSE after Epoch 63: 0.5554\n",
      "Train Epoch: 64 [0/15 (0%)]\tLoss: 0.738971\n",
      "====> Epoch: 64 Average loss: 0.7390\n",
      "====> Validation MSE after Epoch 64: 0.5460\n",
      "Train Epoch: 65 [0/15 (0%)]\tLoss: 0.496881\n",
      "====> Epoch: 65 Average loss: 0.4969\n",
      "====> Validation MSE after Epoch 65: 0.4897\n",
      "Train Epoch: 66 [0/15 (0%)]\tLoss: 0.549358\n",
      "====> Epoch: 66 Average loss: 0.5494\n",
      "====> Validation MSE after Epoch 66: 0.4918\n",
      "Train Epoch: 67 [0/15 (0%)]\tLoss: 0.457518\n",
      "====> Epoch: 67 Average loss: 0.4575\n",
      "====> Validation MSE after Epoch 67: 0.3743\n",
      "Train Epoch: 68 [0/15 (0%)]\tLoss: 0.447231\n",
      "====> Epoch: 68 Average loss: 0.4472\n",
      "====> Validation MSE after Epoch 68: 0.3159\n",
      "Train Epoch: 69 [0/15 (0%)]\tLoss: 0.371344\n",
      "====> Epoch: 69 Average loss: 0.3713\n",
      "====> Validation MSE after Epoch 69: 0.3455\n",
      "Train Epoch: 70 [0/15 (0%)]\tLoss: 0.402836\n",
      "====> Epoch: 70 Average loss: 0.4028\n",
      "====> Validation MSE after Epoch 70: 0.2670\n",
      "Train Epoch: 71 [0/15 (0%)]\tLoss: 0.353486\n",
      "====> Epoch: 71 Average loss: 0.3535\n",
      "====> Validation MSE after Epoch 71: 0.2935\n",
      "Train Epoch: 72 [0/15 (0%)]\tLoss: 0.291897\n",
      "====> Epoch: 72 Average loss: 0.2919\n",
      "====> Validation MSE after Epoch 72: 0.2425\n",
      "Train Epoch: 73 [0/15 (0%)]\tLoss: 0.291746\n",
      "====> Epoch: 73 Average loss: 0.2917\n",
      "====> Validation MSE after Epoch 73: 0.2287\n",
      "Train Epoch: 74 [0/15 (0%)]\tLoss: 0.234943\n",
      "====> Epoch: 74 Average loss: 0.2349\n",
      "====> Validation MSE after Epoch 74: 0.2289\n",
      "Train Epoch: 75 [0/15 (0%)]\tLoss: 0.243695\n",
      "====> Epoch: 75 Average loss: 0.2437\n",
      "====> Validation MSE after Epoch 75: 0.2011\n",
      "Train Epoch: 76 [0/15 (0%)]\tLoss: 0.243371\n",
      "====> Epoch: 76 Average loss: 0.2434\n",
      "====> Validation MSE after Epoch 76: 0.1967\n",
      "Train Epoch: 77 [0/15 (0%)]\tLoss: 0.187101\n",
      "====> Epoch: 77 Average loss: 0.1871\n",
      "====> Validation MSE after Epoch 77: 0.1592\n",
      "Train Epoch: 78 [0/15 (0%)]\tLoss: 0.199532\n",
      "====> Epoch: 78 Average loss: 0.1995\n",
      "====> Validation MSE after Epoch 78: 0.1894\n",
      "Train Epoch: 79 [0/15 (0%)]\tLoss: 0.209110\n",
      "====> Epoch: 79 Average loss: 0.2091\n",
      "====> Validation MSE after Epoch 79: 0.1689\n",
      "Train Epoch: 80 [0/15 (0%)]\tLoss: 0.185204\n",
      "====> Epoch: 80 Average loss: 0.1852\n",
      "====> Validation MSE after Epoch 80: 0.1589\n",
      "Train Epoch: 81 [0/15 (0%)]\tLoss: 0.164641\n",
      "====> Epoch: 81 Average loss: 0.1646\n",
      "====> Validation MSE after Epoch 81: 0.1464\n",
      "Train Epoch: 82 [0/15 (0%)]\tLoss: 0.150125\n",
      "====> Epoch: 82 Average loss: 0.1501\n",
      "====> Validation MSE after Epoch 82: 0.1406\n",
      "Train Epoch: 83 [0/15 (0%)]\tLoss: 0.141981\n",
      "====> Epoch: 83 Average loss: 0.1420\n",
      "====> Validation MSE after Epoch 83: 0.1540\n",
      "Train Epoch: 84 [0/15 (0%)]\tLoss: 0.148394\n",
      "====> Epoch: 84 Average loss: 0.1484\n",
      "====> Validation MSE after Epoch 84: 0.1325\n",
      "Train Epoch: 85 [0/15 (0%)]\tLoss: 0.137025\n",
      "====> Epoch: 85 Average loss: 0.1370\n",
      "====> Validation MSE after Epoch 85: 0.1240\n",
      "Train Epoch: 86 [0/15 (0%)]\tLoss: 0.132825\n",
      "====> Epoch: 86 Average loss: 0.1328\n",
      "====> Validation MSE after Epoch 86: 0.1211\n",
      "Train Epoch: 87 [0/15 (0%)]\tLoss: 0.133122\n",
      "====> Epoch: 87 Average loss: 0.1331\n",
      "====> Validation MSE after Epoch 87: 0.1138\n",
      "Train Epoch: 88 [0/15 (0%)]\tLoss: 0.118403\n",
      "====> Epoch: 88 Average loss: 0.1184\n",
      "====> Validation MSE after Epoch 88: 0.1205\n",
      "Train Epoch: 89 [0/15 (0%)]\tLoss: 0.116096\n",
      "====> Epoch: 89 Average loss: 0.1161\n",
      "====> Validation MSE after Epoch 89: 0.1191\n",
      "Train Epoch: 90 [0/15 (0%)]\tLoss: 0.115271\n",
      "====> Epoch: 90 Average loss: 0.1153\n",
      "====> Validation MSE after Epoch 90: 0.1155\n",
      "Train Epoch: 91 [0/15 (0%)]\tLoss: 0.111422\n",
      "====> Epoch: 91 Average loss: 0.1114\n",
      "====> Validation MSE after Epoch 91: 0.1157\n",
      "Train Epoch: 92 [0/15 (0%)]\tLoss: 0.115019\n",
      "====> Epoch: 92 Average loss: 0.1150\n",
      "====> Validation MSE after Epoch 92: 0.1070\n",
      "Train Epoch: 93 [0/15 (0%)]\tLoss: 0.105344\n",
      "====> Epoch: 93 Average loss: 0.1053\n",
      "====> Validation MSE after Epoch 93: 0.1084\n",
      "Train Epoch: 94 [0/15 (0%)]\tLoss: 0.106310\n",
      "====> Epoch: 94 Average loss: 0.1063\n",
      "====> Validation MSE after Epoch 94: 0.1052\n",
      "Train Epoch: 95 [0/15 (0%)]\tLoss: 0.105739\n",
      "====> Epoch: 95 Average loss: 0.1057\n",
      "====> Validation MSE after Epoch 95: 0.1048\n",
      "Train Epoch: 96 [0/15 (0%)]\tLoss: 0.107107\n",
      "====> Epoch: 96 Average loss: 0.1071\n",
      "====> Validation MSE after Epoch 96: 0.1049\n",
      "Train Epoch: 97 [0/15 (0%)]\tLoss: 0.105215\n",
      "====> Epoch: 97 Average loss: 0.1052\n",
      "====> Validation MSE after Epoch 97: 0.1067\n",
      "Train Epoch: 98 [0/15 (0%)]\tLoss: 0.105108\n",
      "====> Epoch: 98 Average loss: 0.1051\n",
      "====> Validation MSE after Epoch 98: 0.1064\n",
      "Train Epoch: 99 [0/15 (0%)]\tLoss: 0.105432\n",
      "====> Epoch: 99 Average loss: 0.1054\n",
      "====> Validation MSE after Epoch 99: 0.1042\n",
      "Train Epoch: 100 [0/15 (0%)]\tLoss: 0.104303\n",
      "====> Epoch: 100 Average loss: 0.1043\n",
      "====> Validation MSE after Epoch 100: 0.1032\n",
      "Training model for group: patient\n",
      "Train Epoch: 1 [0/113 (0%)]\tLoss: 12.887429\n",
      "====> Epoch: 1 Average loss: 12.4321\n",
      "====> Validation MSE after Epoch 1: 11.6731\n",
      "Train Epoch: 2 [0/113 (0%)]\tLoss: 11.806145\n",
      "====> Epoch: 2 Average loss: 11.4095\n",
      "====> Validation MSE after Epoch 2: 10.6895\n",
      "Train Epoch: 3 [0/113 (0%)]\tLoss: 10.738408\n",
      "====> Epoch: 3 Average loss: 10.3771\n",
      "====> Validation MSE after Epoch 3: 9.5832\n",
      "Train Epoch: 4 [0/113 (0%)]\tLoss: 9.609849\n",
      "====> Epoch: 4 Average loss: 9.1940\n",
      "====> Validation MSE after Epoch 4: 8.4412\n",
      "Train Epoch: 5 [0/113 (0%)]\tLoss: 8.539936\n",
      "====> Epoch: 5 Average loss: 8.1622\n",
      "====> Validation MSE after Epoch 5: 7.2212\n",
      "Train Epoch: 6 [0/113 (0%)]\tLoss: 7.247025\n",
      "====> Epoch: 6 Average loss: 7.0719\n",
      "====> Validation MSE after Epoch 6: 6.0809\n",
      "Train Epoch: 7 [0/113 (0%)]\tLoss: 6.151769\n",
      "====> Epoch: 7 Average loss: 5.8583\n",
      "====> Validation MSE after Epoch 7: 5.0280\n",
      "Train Epoch: 8 [0/113 (0%)]\tLoss: 4.938865\n",
      "====> Epoch: 8 Average loss: 4.5889\n",
      "====> Validation MSE after Epoch 8: 3.9210\n",
      "Train Epoch: 9 [0/113 (0%)]\tLoss: 4.085729\n",
      "====> Epoch: 9 Average loss: 3.7753\n",
      "====> Validation MSE after Epoch 9: 2.9121\n",
      "Train Epoch: 10 [0/113 (0%)]\tLoss: 3.092114\n",
      "====> Epoch: 10 Average loss: 2.8294\n",
      "====> Validation MSE after Epoch 10: 2.2583\n",
      "Train Epoch: 11 [0/113 (0%)]\tLoss: 2.141811\n",
      "====> Epoch: 11 Average loss: 2.0310\n",
      "====> Validation MSE after Epoch 11: 1.5857\n",
      "Train Epoch: 12 [0/113 (0%)]\tLoss: 1.636125\n",
      "====> Epoch: 12 Average loss: 1.4808\n",
      "====> Validation MSE after Epoch 12: 1.0523\n",
      "Train Epoch: 13 [0/113 (0%)]\tLoss: 1.147843\n",
      "====> Epoch: 13 Average loss: 1.0391\n",
      "====> Validation MSE after Epoch 13: 0.7212\n",
      "Train Epoch: 14 [0/113 (0%)]\tLoss: 0.713579\n",
      "====> Epoch: 14 Average loss: 0.7280\n",
      "====> Validation MSE after Epoch 14: 0.4694\n",
      "Train Epoch: 15 [0/113 (0%)]\tLoss: 0.545068\n",
      "====> Epoch: 15 Average loss: 0.4861\n",
      "====> Validation MSE after Epoch 15: 0.3715\n",
      "Train Epoch: 16 [0/113 (0%)]\tLoss: 0.338709\n",
      "====> Epoch: 16 Average loss: 0.3393\n",
      "====> Validation MSE after Epoch 16: 0.2676\n",
      "Train Epoch: 17 [0/113 (0%)]\tLoss: 0.289206\n",
      "====> Epoch: 17 Average loss: 0.2620\n",
      "====> Validation MSE after Epoch 17: 0.2174\n",
      "Train Epoch: 18 [0/113 (0%)]\tLoss: 0.217839\n",
      "====> Epoch: 18 Average loss: 0.2047\n",
      "====> Validation MSE after Epoch 18: 0.1819\n",
      "Train Epoch: 19 [0/113 (0%)]\tLoss: 0.170933\n",
      "====> Epoch: 19 Average loss: 0.1754\n",
      "====> Validation MSE after Epoch 19: 0.1642\n",
      "Train Epoch: 20 [0/113 (0%)]\tLoss: 0.158897\n",
      "====> Epoch: 20 Average loss: 0.1628\n",
      "====> Validation MSE after Epoch 20: 0.1563\n",
      "Train Epoch: 21 [0/113 (0%)]\tLoss: 0.148325\n",
      "====> Epoch: 21 Average loss: 0.1529\n",
      "====> Validation MSE after Epoch 21: 0.1495\n",
      "Train Epoch: 22 [0/113 (0%)]\tLoss: 0.157995\n",
      "====> Epoch: 22 Average loss: 0.1491\n",
      "====> Validation MSE after Epoch 22: 0.1487\n",
      "Train Epoch: 23 [0/113 (0%)]\tLoss: 0.176018\n",
      "====> Epoch: 23 Average loss: 0.1475\n",
      "====> Validation MSE after Epoch 23: 0.1467\n",
      "Train Epoch: 24 [0/113 (0%)]\tLoss: 0.118010\n",
      "====> Epoch: 24 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 24: 0.1456\n",
      "Train Epoch: 25 [0/113 (0%)]\tLoss: 0.116609\n",
      "====> Epoch: 25 Average loss: 0.1456\n",
      "====> Validation MSE after Epoch 25: 0.1453\n",
      "Train Epoch: 26 [0/113 (0%)]\tLoss: 0.125872\n",
      "====> Epoch: 26 Average loss: 0.1450\n",
      "====> Validation MSE after Epoch 26: 0.1448\n",
      "Train Epoch: 27 [0/113 (0%)]\tLoss: 0.123208\n",
      "====> Epoch: 27 Average loss: 0.1450\n",
      "====> Validation MSE after Epoch 27: 0.1449\n",
      "Train Epoch: 28 [0/113 (0%)]\tLoss: 0.146751\n",
      "====> Epoch: 28 Average loss: 0.1448\n",
      "====> Validation MSE after Epoch 28: 0.1447\n",
      "Train Epoch: 29 [0/113 (0%)]\tLoss: 0.134880\n",
      "====> Epoch: 29 Average loss: 0.1450\n",
      "====> Validation MSE after Epoch 29: 0.1444\n",
      "Train Epoch: 30 [0/113 (0%)]\tLoss: 0.150741\n",
      "====> Epoch: 30 Average loss: 0.1447\n",
      "====> Validation MSE after Epoch 30: 0.1445\n",
      "Train Epoch: 31 [0/113 (0%)]\tLoss: 0.147650\n",
      "====> Epoch: 31 Average loss: 0.1444\n",
      "====> Validation MSE after Epoch 31: 0.1445\n",
      "Train Epoch: 32 [0/113 (0%)]\tLoss: 0.120971\n",
      "====> Epoch: 32 Average loss: 0.1446\n",
      "====> Validation MSE after Epoch 32: 0.1443\n",
      "Train Epoch: 33 [0/113 (0%)]\tLoss: 0.174521\n",
      "====> Epoch: 33 Average loss: 0.1447\n",
      "====> Validation MSE after Epoch 33: 0.1443\n",
      "Train Epoch: 34 [0/113 (0%)]\tLoss: 0.152296\n",
      "====> Epoch: 34 Average loss: 0.1444\n",
      "====> Validation MSE after Epoch 34: 0.1447\n",
      "Train Epoch: 35 [0/113 (0%)]\tLoss: 0.152850\n",
      "====> Epoch: 35 Average loss: 0.1443\n",
      "====> Validation MSE after Epoch 35: 0.1445\n",
      "Train Epoch: 36 [0/113 (0%)]\tLoss: 0.150161\n",
      "====> Epoch: 36 Average loss: 0.1445\n",
      "====> Validation MSE after Epoch 36: 0.1441\n",
      "Train Epoch: 37 [0/113 (0%)]\tLoss: 0.152751\n",
      "====> Epoch: 37 Average loss: 0.1444\n",
      "====> Validation MSE after Epoch 37: 0.1441\n",
      "Train Epoch: 38 [0/113 (0%)]\tLoss: 0.162094\n",
      "====> Epoch: 38 Average loss: 0.1443\n",
      "====> Validation MSE after Epoch 38: 0.1442\n",
      "Train Epoch: 39 [0/113 (0%)]\tLoss: 0.182198\n",
      "====> Epoch: 39 Average loss: 0.1442\n",
      "====> Validation MSE after Epoch 39: 0.1443\n",
      "Train Epoch: 40 [0/113 (0%)]\tLoss: 0.146225\n",
      "====> Epoch: 40 Average loss: 0.1443\n",
      "====> Validation MSE after Epoch 40: 0.1443\n",
      "Train Epoch: 41 [0/113 (0%)]\tLoss: 0.114461\n",
      "====> Epoch: 41 Average loss: 0.1445\n",
      "====> Validation MSE after Epoch 41: 0.1440\n",
      "Train Epoch: 42 [0/113 (0%)]\tLoss: 0.139256\n",
      "====> Epoch: 42 Average loss: 0.1443\n",
      "====> Validation MSE after Epoch 42: 0.1444\n",
      "Train Epoch: 43 [0/113 (0%)]\tLoss: 0.130414\n",
      "====> Epoch: 43 Average loss: 0.1444\n",
      "====> Validation MSE after Epoch 43: 0.1443\n",
      "Train Epoch: 44 [0/113 (0%)]\tLoss: 0.151215\n",
      "====> Epoch: 44 Average loss: 0.1443\n",
      "====> Validation MSE after Epoch 44: 0.1445\n",
      "Train Epoch: 45 [0/113 (0%)]\tLoss: 0.124355\n",
      "====> Epoch: 45 Average loss: 0.1442\n",
      "====> Validation MSE after Epoch 45: 0.1442\n",
      "Train Epoch: 46 [0/113 (0%)]\tLoss: 0.193498\n",
      "====> Epoch: 46 Average loss: 0.1442\n",
      "====> Validation MSE after Epoch 46: 0.1444\n",
      "Train Epoch: 47 [0/113 (0%)]\tLoss: 0.152676\n",
      "====> Epoch: 47 Average loss: 0.1448\n",
      "====> Validation MSE after Epoch 47: 0.1441\n",
      "Train Epoch: 48 [0/113 (0%)]\tLoss: 0.158195\n",
      "====> Epoch: 48 Average loss: 0.1441\n",
      "====> Validation MSE after Epoch 48: 0.1442\n",
      "Train Epoch: 49 [0/113 (0%)]\tLoss: 0.160875\n",
      "====> Epoch: 49 Average loss: 0.1443\n",
      "====> Validation MSE after Epoch 49: 0.1441\n",
      "Train Epoch: 50 [0/113 (0%)]\tLoss: 0.111197\n",
      "====> Epoch: 50 Average loss: 0.1443\n",
      "====> Validation MSE after Epoch 50: 0.1441\n",
      "Train Epoch: 51 [0/113 (0%)]\tLoss: 0.128150\n",
      "====> Epoch: 51 Average loss: 0.1441\n",
      "====> Validation MSE after Epoch 51: 0.1443\n",
      "Train Epoch: 52 [0/113 (0%)]\tLoss: 0.177491\n",
      "====> Epoch: 52 Average loss: 0.1442\n",
      "====> Validation MSE after Epoch 52: 0.1441\n",
      "Train Epoch: 53 [0/113 (0%)]\tLoss: 0.136623\n",
      "====> Epoch: 53 Average loss: 0.1444\n",
      "====> Validation MSE after Epoch 53: 0.1441\n",
      "Train Epoch: 54 [0/113 (0%)]\tLoss: 0.157427\n",
      "====> Epoch: 54 Average loss: 0.1442\n",
      "====> Validation MSE after Epoch 54: 0.1441\n",
      "Train Epoch: 55 [0/113 (0%)]\tLoss: 0.131736\n",
      "====> Epoch: 55 Average loss: 0.1441\n",
      "====> Validation MSE after Epoch 55: 0.1443\n",
      "Train Epoch: 56 [0/113 (0%)]\tLoss: 0.133433\n",
      "====> Epoch: 56 Average loss: 0.1443\n",
      "====> Validation MSE after Epoch 56: 0.1439\n",
      "Train Epoch: 57 [0/113 (0%)]\tLoss: 0.155365\n",
      "====> Epoch: 57 Average loss: 0.1442\n",
      "====> Validation MSE after Epoch 57: 0.1441\n",
      "Train Epoch: 58 [0/113 (0%)]\tLoss: 0.109656\n",
      "====> Epoch: 58 Average loss: 0.1444\n",
      "====> Validation MSE after Epoch 58: 0.1443\n",
      "Train Epoch: 59 [0/113 (0%)]\tLoss: 0.139844\n",
      "====> Epoch: 59 Average loss: 0.1440\n",
      "====> Validation MSE after Epoch 59: 0.1441\n",
      "Train Epoch: 60 [0/113 (0%)]\tLoss: 0.156766\n",
      "====> Epoch: 60 Average loss: 0.1444\n",
      "====> Validation MSE after Epoch 60: 0.1442\n",
      "Train Epoch: 61 [0/113 (0%)]\tLoss: 0.135928\n",
      "====> Epoch: 61 Average loss: 0.1442\n",
      "====> Validation MSE after Epoch 61: 0.1442\n",
      "Train Epoch: 62 [0/113 (0%)]\tLoss: 0.138892\n",
      "====> Epoch: 62 Average loss: 0.1439\n",
      "====> Validation MSE after Epoch 62: 0.1441\n",
      "Train Epoch: 63 [0/113 (0%)]\tLoss: 0.132230\n",
      "====> Epoch: 63 Average loss: 0.1441\n",
      "====> Validation MSE after Epoch 63: 0.1444\n",
      "Train Epoch: 64 [0/113 (0%)]\tLoss: 0.156518\n",
      "====> Epoch: 64 Average loss: 0.1441\n",
      "====> Validation MSE after Epoch 64: 0.1443\n",
      "Train Epoch: 65 [0/113 (0%)]\tLoss: 0.148901\n",
      "====> Epoch: 65 Average loss: 0.1442\n",
      "====> Validation MSE after Epoch 65: 0.1442\n",
      "Train Epoch: 66 [0/113 (0%)]\tLoss: 0.124062\n",
      "====> Epoch: 66 Average loss: 0.1443\n",
      "====> Validation MSE after Epoch 66: 0.1442\n",
      "Train Epoch: 67 [0/113 (0%)]\tLoss: 0.142016\n",
      "====> Epoch: 67 Average loss: 0.1441\n",
      "====> Validation MSE after Epoch 67: 0.1440\n",
      "Train Epoch: 68 [0/113 (0%)]\tLoss: 0.187406\n",
      "====> Epoch: 68 Average loss: 0.1444\n",
      "====> Validation MSE after Epoch 68: 0.1443\n",
      "Train Epoch: 69 [0/113 (0%)]\tLoss: 0.152184\n",
      "====> Epoch: 69 Average loss: 0.1442\n",
      "====> Validation MSE after Epoch 69: 0.1441\n",
      "Train Epoch: 70 [0/113 (0%)]\tLoss: 0.148628\n",
      "====> Epoch: 70 Average loss: 0.1443\n",
      "====> Validation MSE after Epoch 70: 0.1442\n",
      "Train Epoch: 71 [0/113 (0%)]\tLoss: 0.120465\n",
      "====> Epoch: 71 Average loss: 0.1441\n",
      "====> Validation MSE after Epoch 71: 0.1441\n",
      "Train Epoch: 72 [0/113 (0%)]\tLoss: 0.151797\n",
      "====> Epoch: 72 Average loss: 0.1440\n",
      "====> Validation MSE after Epoch 72: 0.1442\n",
      "Train Epoch: 73 [0/113 (0%)]\tLoss: 0.145333\n",
      "====> Epoch: 73 Average loss: 0.1441\n",
      "====> Validation MSE after Epoch 73: 0.1439\n",
      "Train Epoch: 74 [0/113 (0%)]\tLoss: 0.149459\n",
      "====> Epoch: 74 Average loss: 0.1441\n",
      "====> Validation MSE after Epoch 74: 0.1439\n",
      "Train Epoch: 75 [0/113 (0%)]\tLoss: 0.134240\n",
      "====> Epoch: 75 Average loss: 0.1440\n",
      "====> Validation MSE after Epoch 75: 0.1439\n",
      "Train Epoch: 76 [0/113 (0%)]\tLoss: 0.132330\n",
      "====> Epoch: 76 Average loss: 0.1438\n",
      "====> Validation MSE after Epoch 76: 0.1442\n",
      "Train Epoch: 77 [0/113 (0%)]\tLoss: 0.115338\n",
      "====> Epoch: 77 Average loss: 0.1440\n",
      "====> Validation MSE after Epoch 77: 0.1441\n",
      "Train Epoch: 78 [0/113 (0%)]\tLoss: 0.131686\n",
      "====> Epoch: 78 Average loss: 0.1440\n",
      "====> Validation MSE after Epoch 78: 0.1440\n",
      "Train Epoch: 79 [0/113 (0%)]\tLoss: 0.156471\n",
      "====> Epoch: 79 Average loss: 0.1439\n",
      "====> Validation MSE after Epoch 79: 0.1440\n",
      "Train Epoch: 80 [0/113 (0%)]\tLoss: 0.108914\n",
      "====> Epoch: 80 Average loss: 0.1440\n",
      "====> Validation MSE after Epoch 80: 0.1438\n",
      "Train Epoch: 81 [0/113 (0%)]\tLoss: 0.118359\n",
      "====> Epoch: 81 Average loss: 0.1440\n",
      "====> Validation MSE after Epoch 81: 0.1441\n",
      "Train Epoch: 82 [0/113 (0%)]\tLoss: 0.182663\n",
      "====> Epoch: 82 Average loss: 0.1441\n",
      "====> Validation MSE after Epoch 82: 0.1441\n",
      "Train Epoch: 83 [0/113 (0%)]\tLoss: 0.127828\n",
      "====> Epoch: 83 Average loss: 0.1440\n",
      "====> Validation MSE after Epoch 83: 0.1441\n",
      "Train Epoch: 84 [0/113 (0%)]\tLoss: 0.144193\n",
      "====> Epoch: 84 Average loss: 0.1440\n",
      "====> Validation MSE after Epoch 84: 0.1440\n",
      "Train Epoch: 85 [0/113 (0%)]\tLoss: 0.112478\n",
      "====> Epoch: 85 Average loss: 0.1439\n",
      "====> Validation MSE after Epoch 85: 0.1441\n",
      "Train Epoch: 86 [0/113 (0%)]\tLoss: 0.147509\n",
      "====> Epoch: 86 Average loss: 0.1439\n",
      "====> Validation MSE after Epoch 86: 0.1438\n",
      "Train Epoch: 87 [0/113 (0%)]\tLoss: 0.135558\n",
      "====> Epoch: 87 Average loss: 0.1440\n",
      "====> Validation MSE after Epoch 87: 0.1440\n",
      "Train Epoch: 88 [0/113 (0%)]\tLoss: 0.109628\n",
      "====> Epoch: 88 Average loss: 0.1443\n",
      "====> Validation MSE after Epoch 88: 0.1437\n",
      "Train Epoch: 89 [0/113 (0%)]\tLoss: 0.138334\n",
      "====> Epoch: 89 Average loss: 0.1441\n",
      "====> Validation MSE after Epoch 89: 0.1442\n",
      "Train Epoch: 90 [0/113 (0%)]\tLoss: 0.127193\n",
      "====> Epoch: 90 Average loss: 0.1442\n",
      "====> Validation MSE after Epoch 90: 0.1441\n",
      "Train Epoch: 91 [0/113 (0%)]\tLoss: 0.143885\n",
      "====> Epoch: 91 Average loss: 0.1440\n",
      "====> Validation MSE after Epoch 91: 0.1442\n",
      "Train Epoch: 92 [0/113 (0%)]\tLoss: 0.142675\n",
      "====> Epoch: 92 Average loss: 0.1439\n",
      "====> Validation MSE after Epoch 92: 0.1438\n",
      "Train Epoch: 93 [0/113 (0%)]\tLoss: 0.133750\n",
      "====> Epoch: 93 Average loss: 0.1440\n",
      "====> Validation MSE after Epoch 93: 0.1437\n",
      "Train Epoch: 94 [0/113 (0%)]\tLoss: 0.138473\n",
      "====> Epoch: 94 Average loss: 0.1439\n",
      "====> Validation MSE after Epoch 94: 0.1436\n",
      "Train Epoch: 95 [0/113 (0%)]\tLoss: 0.125535\n",
      "====> Epoch: 95 Average loss: 0.1440\n",
      "====> Validation MSE after Epoch 95: 0.1441\n",
      "Train Epoch: 96 [0/113 (0%)]\tLoss: 0.144947\n",
      "====> Epoch: 96 Average loss: 0.1440\n",
      "====> Validation MSE after Epoch 96: 0.1438\n",
      "Train Epoch: 97 [0/113 (0%)]\tLoss: 0.158579\n",
      "====> Epoch: 97 Average loss: 0.1441\n",
      "====> Validation MSE after Epoch 97: 0.1439\n",
      "Train Epoch: 98 [0/113 (0%)]\tLoss: 0.122844\n",
      "====> Epoch: 98 Average loss: 0.1437\n",
      "====> Validation MSE after Epoch 98: 0.1442\n",
      "Train Epoch: 99 [0/113 (0%)]\tLoss: 0.149486\n",
      "====> Epoch: 99 Average loss: 0.1439\n",
      "====> Validation MSE after Epoch 99: 0.1436\n",
      "Train Epoch: 100 [0/113 (0%)]\tLoss: 0.163397\n",
      "====> Epoch: 100 Average loss: 0.1439\n",
      "====> Validation MSE after Epoch 100: 0.1440\n",
      "Training model for group: prodromal\n",
      "Train Epoch: 1 [0/67 (0%)]\tLoss: 15.105386\n",
      "====> Epoch: 1 Average loss: 14.9132\n",
      "====> Validation MSE after Epoch 1: 14.0901\n",
      "Train Epoch: 2 [0/67 (0%)]\tLoss: 14.170954\n",
      "====> Epoch: 2 Average loss: 13.9848\n",
      "====> Validation MSE after Epoch 2: 13.2470\n",
      "Train Epoch: 3 [0/67 (0%)]\tLoss: 13.222870\n",
      "====> Epoch: 3 Average loss: 13.1825\n",
      "====> Validation MSE after Epoch 3: 12.4508\n",
      "Train Epoch: 4 [0/67 (0%)]\tLoss: 12.488028\n",
      "====> Epoch: 4 Average loss: 12.3964\n",
      "====> Validation MSE after Epoch 4: 11.6897\n",
      "Train Epoch: 5 [0/67 (0%)]\tLoss: 11.637722\n",
      "====> Epoch: 5 Average loss: 11.5100\n",
      "====> Validation MSE after Epoch 5: 10.8228\n",
      "Train Epoch: 6 [0/67 (0%)]\tLoss: 10.791841\n",
      "====> Epoch: 6 Average loss: 10.7624\n",
      "====> Validation MSE after Epoch 6: 10.0900\n",
      "Train Epoch: 7 [0/67 (0%)]\tLoss: 10.043582\n",
      "====> Epoch: 7 Average loss: 10.0054\n",
      "====> Validation MSE after Epoch 7: 9.2931\n",
      "Train Epoch: 8 [0/67 (0%)]\tLoss: 9.118808\n",
      "====> Epoch: 8 Average loss: 9.0348\n",
      "====> Validation MSE after Epoch 8: 8.4046\n",
      "Train Epoch: 9 [0/67 (0%)]\tLoss: 8.713893\n",
      "====> Epoch: 9 Average loss: 8.5193\n",
      "====> Validation MSE after Epoch 9: 7.6324\n",
      "Train Epoch: 10 [0/67 (0%)]\tLoss: 7.924406\n",
      "====> Epoch: 10 Average loss: 7.6581\n",
      "====> Validation MSE after Epoch 10: 6.7942\n",
      "Train Epoch: 11 [0/67 (0%)]\tLoss: 7.080559\n",
      "====> Epoch: 11 Average loss: 6.8614\n",
      "====> Validation MSE after Epoch 11: 6.0113\n",
      "Train Epoch: 12 [0/67 (0%)]\tLoss: 6.161058\n",
      "====> Epoch: 12 Average loss: 5.9025\n",
      "====> Validation MSE after Epoch 12: 5.2091\n",
      "Train Epoch: 13 [0/67 (0%)]\tLoss: 5.497142\n",
      "====> Epoch: 13 Average loss: 5.3620\n",
      "====> Validation MSE after Epoch 13: 4.3629\n",
      "Train Epoch: 14 [0/67 (0%)]\tLoss: 4.755199\n",
      "====> Epoch: 14 Average loss: 4.6277\n",
      "====> Validation MSE after Epoch 14: 3.7904\n",
      "Train Epoch: 15 [0/67 (0%)]\tLoss: 3.807770\n",
      "====> Epoch: 15 Average loss: 3.6478\n",
      "====> Validation MSE after Epoch 15: 3.1086\n",
      "Train Epoch: 16 [0/67 (0%)]\tLoss: 3.078600\n",
      "====> Epoch: 16 Average loss: 2.9630\n",
      "====> Validation MSE after Epoch 16: 2.5829\n",
      "Train Epoch: 17 [0/67 (0%)]\tLoss: 2.774265\n",
      "====> Epoch: 17 Average loss: 2.7118\n",
      "====> Validation MSE after Epoch 17: 2.1022\n",
      "Train Epoch: 18 [0/67 (0%)]\tLoss: 2.106530\n",
      "====> Epoch: 18 Average loss: 2.1299\n",
      "====> Validation MSE after Epoch 18: 1.5803\n",
      "Train Epoch: 19 [0/67 (0%)]\tLoss: 1.721077\n",
      "====> Epoch: 19 Average loss: 1.7309\n",
      "====> Validation MSE after Epoch 19: 1.2818\n",
      "Train Epoch: 20 [0/67 (0%)]\tLoss: 1.267510\n",
      "====> Epoch: 20 Average loss: 1.2711\n",
      "====> Validation MSE after Epoch 20: 0.9975\n",
      "Train Epoch: 21 [0/67 (0%)]\tLoss: 0.977640\n",
      "====> Epoch: 21 Average loss: 0.9598\n",
      "====> Validation MSE after Epoch 21: 0.7450\n",
      "Train Epoch: 22 [0/67 (0%)]\tLoss: 0.819831\n",
      "====> Epoch: 22 Average loss: 0.7930\n",
      "====> Validation MSE after Epoch 22: 0.6055\n",
      "Train Epoch: 23 [0/67 (0%)]\tLoss: 0.556637\n",
      "====> Epoch: 23 Average loss: 0.5582\n",
      "====> Validation MSE after Epoch 23: 0.4895\n",
      "Train Epoch: 24 [0/67 (0%)]\tLoss: 0.491072\n",
      "====> Epoch: 24 Average loss: 0.5069\n",
      "====> Validation MSE after Epoch 24: 0.3548\n",
      "Train Epoch: 25 [0/67 (0%)]\tLoss: 0.489531\n",
      "====> Epoch: 25 Average loss: 0.3736\n",
      "====> Validation MSE after Epoch 25: 0.3026\n",
      "Train Epoch: 26 [0/67 (0%)]\tLoss: 0.382172\n",
      "====> Epoch: 26 Average loss: 0.3204\n",
      "====> Validation MSE after Epoch 26: 0.2334\n",
      "Train Epoch: 27 [0/67 (0%)]\tLoss: 0.218493\n",
      "====> Epoch: 27 Average loss: 0.2622\n",
      "====> Validation MSE after Epoch 27: 0.2209\n",
      "Train Epoch: 28 [0/67 (0%)]\tLoss: 0.219877\n",
      "====> Epoch: 28 Average loss: 0.2103\n",
      "====> Validation MSE after Epoch 28: 0.2013\n",
      "Train Epoch: 29 [0/67 (0%)]\tLoss: 0.146250\n",
      "====> Epoch: 29 Average loss: 0.1906\n",
      "====> Validation MSE after Epoch 29: 0.1788\n",
      "Train Epoch: 30 [0/67 (0%)]\tLoss: 0.160807\n",
      "====> Epoch: 30 Average loss: 0.1812\n",
      "====> Validation MSE after Epoch 30: 0.1620\n",
      "Train Epoch: 31 [0/67 (0%)]\tLoss: 0.167494\n",
      "====> Epoch: 31 Average loss: 0.1699\n",
      "====> Validation MSE after Epoch 31: 0.1616\n",
      "Train Epoch: 32 [0/67 (0%)]\tLoss: 0.125940\n",
      "====> Epoch: 32 Average loss: 0.1594\n",
      "====> Validation MSE after Epoch 32: 0.1532\n",
      "Train Epoch: 33 [0/67 (0%)]\tLoss: 0.156849\n",
      "====> Epoch: 33 Average loss: 0.1558\n",
      "====> Validation MSE after Epoch 33: 0.1516\n",
      "Train Epoch: 34 [0/67 (0%)]\tLoss: 0.174261\n",
      "====> Epoch: 34 Average loss: 0.1503\n",
      "====> Validation MSE after Epoch 34: 0.1502\n",
      "Train Epoch: 35 [0/67 (0%)]\tLoss: 0.110171\n",
      "====> Epoch: 35 Average loss: 0.1513\n",
      "====> Validation MSE after Epoch 35: 0.1478\n",
      "Train Epoch: 36 [0/67 (0%)]\tLoss: 0.162499\n",
      "====> Epoch: 36 Average loss: 0.1482\n",
      "====> Validation MSE after Epoch 36: 0.1472\n",
      "Train Epoch: 37 [0/67 (0%)]\tLoss: 0.139435\n",
      "====> Epoch: 37 Average loss: 0.1471\n",
      "====> Validation MSE after Epoch 37: 0.1469\n",
      "Train Epoch: 38 [0/67 (0%)]\tLoss: 0.171813\n",
      "====> Epoch: 38 Average loss: 0.1470\n",
      "====> Validation MSE after Epoch 38: 0.1466\n",
      "Train Epoch: 39 [0/67 (0%)]\tLoss: 0.140939\n",
      "====> Epoch: 39 Average loss: 0.1465\n",
      "====> Validation MSE after Epoch 39: 0.1466\n",
      "Train Epoch: 40 [0/67 (0%)]\tLoss: 0.132980\n",
      "====> Epoch: 40 Average loss: 0.1466\n",
      "====> Validation MSE after Epoch 40: 0.1464\n",
      "Train Epoch: 41 [0/67 (0%)]\tLoss: 0.151563\n",
      "====> Epoch: 41 Average loss: 0.1463\n",
      "====> Validation MSE after Epoch 41: 0.1464\n",
      "Train Epoch: 42 [0/67 (0%)]\tLoss: 0.158993\n",
      "====> Epoch: 42 Average loss: 0.1464\n",
      "====> Validation MSE after Epoch 42: 0.1465\n",
      "Train Epoch: 43 [0/67 (0%)]\tLoss: 0.149204\n",
      "====> Epoch: 43 Average loss: 0.1467\n",
      "====> Validation MSE after Epoch 43: 0.1463\n",
      "Train Epoch: 44 [0/67 (0%)]\tLoss: 0.138581\n",
      "====> Epoch: 44 Average loss: 0.1466\n",
      "====> Validation MSE after Epoch 44: 0.1460\n",
      "Train Epoch: 45 [0/67 (0%)]\tLoss: 0.172828\n",
      "====> Epoch: 45 Average loss: 0.1463\n",
      "====> Validation MSE after Epoch 45: 0.1461\n",
      "Train Epoch: 46 [0/67 (0%)]\tLoss: 0.145532\n",
      "====> Epoch: 46 Average loss: 0.1462\n",
      "====> Validation MSE after Epoch 46: 0.1461\n",
      "Train Epoch: 47 [0/67 (0%)]\tLoss: 0.189442\n",
      "====> Epoch: 47 Average loss: 0.1462\n",
      "====> Validation MSE after Epoch 47: 0.1461\n",
      "Train Epoch: 48 [0/67 (0%)]\tLoss: 0.158630\n",
      "====> Epoch: 48 Average loss: 0.1462\n",
      "====> Validation MSE after Epoch 48: 0.1462\n",
      "Train Epoch: 49 [0/67 (0%)]\tLoss: 0.153182\n",
      "====> Epoch: 49 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 49: 0.1461\n",
      "Train Epoch: 50 [0/67 (0%)]\tLoss: 0.164784\n",
      "====> Epoch: 50 Average loss: 0.1461\n",
      "====> Validation MSE after Epoch 50: 0.1461\n",
      "Train Epoch: 51 [0/67 (0%)]\tLoss: 0.148241\n",
      "====> Epoch: 51 Average loss: 0.1462\n",
      "====> Validation MSE after Epoch 51: 0.1459\n",
      "Train Epoch: 52 [0/67 (0%)]\tLoss: 0.125827\n",
      "====> Epoch: 52 Average loss: 0.1460\n",
      "====> Validation MSE after Epoch 52: 0.1461\n",
      "Train Epoch: 53 [0/67 (0%)]\tLoss: 0.124506\n",
      "====> Epoch: 53 Average loss: 0.1460\n",
      "====> Validation MSE after Epoch 53: 0.1457\n",
      "Train Epoch: 54 [0/67 (0%)]\tLoss: 0.163950\n",
      "====> Epoch: 54 Average loss: 0.1460\n",
      "====> Validation MSE after Epoch 54: 0.1458\n",
      "Train Epoch: 55 [0/67 (0%)]\tLoss: 0.148782\n",
      "====> Epoch: 55 Average loss: 0.1460\n",
      "====> Validation MSE after Epoch 55: 0.1459\n",
      "Train Epoch: 56 [0/67 (0%)]\tLoss: 0.118129\n",
      "====> Epoch: 56 Average loss: 0.1461\n",
      "====> Validation MSE after Epoch 56: 0.1460\n",
      "Train Epoch: 57 [0/67 (0%)]\tLoss: 0.185031\n",
      "====> Epoch: 57 Average loss: 0.1460\n",
      "====> Validation MSE after Epoch 57: 0.1460\n",
      "Train Epoch: 58 [0/67 (0%)]\tLoss: 0.111342\n",
      "====> Epoch: 58 Average loss: 0.1460\n",
      "====> Validation MSE after Epoch 58: 0.1461\n",
      "Train Epoch: 59 [0/67 (0%)]\tLoss: 0.196975\n",
      "====> Epoch: 59 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 59: 0.1461\n",
      "Train Epoch: 60 [0/67 (0%)]\tLoss: 0.131030\n",
      "====> Epoch: 60 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 60: 0.1459\n",
      "Train Epoch: 61 [0/67 (0%)]\tLoss: 0.104724\n",
      "====> Epoch: 61 Average loss: 0.1460\n",
      "====> Validation MSE after Epoch 61: 0.1459\n",
      "Train Epoch: 62 [0/67 (0%)]\tLoss: 0.136881\n",
      "====> Epoch: 62 Average loss: 0.1460\n",
      "====> Validation MSE after Epoch 62: 0.1459\n",
      "Train Epoch: 63 [0/67 (0%)]\tLoss: 0.126118\n",
      "====> Epoch: 63 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 63: 0.1461\n",
      "Train Epoch: 64 [0/67 (0%)]\tLoss: 0.119246\n",
      "====> Epoch: 64 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 64: 0.1458\n",
      "Train Epoch: 65 [0/67 (0%)]\tLoss: 0.129255\n",
      "====> Epoch: 65 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 65: 0.1460\n",
      "Train Epoch: 66 [0/67 (0%)]\tLoss: 0.128784\n",
      "====> Epoch: 66 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 66: 0.1460\n",
      "Train Epoch: 67 [0/67 (0%)]\tLoss: 0.163904\n",
      "====> Epoch: 67 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 67: 0.1459\n",
      "Train Epoch: 68 [0/67 (0%)]\tLoss: 0.154558\n",
      "====> Epoch: 68 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 68: 0.1459\n",
      "Train Epoch: 69 [0/67 (0%)]\tLoss: 0.110583\n",
      "====> Epoch: 69 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 69: 0.1459\n",
      "Train Epoch: 70 [0/67 (0%)]\tLoss: 0.179578\n",
      "====> Epoch: 70 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 70: 0.1460\n",
      "Train Epoch: 71 [0/67 (0%)]\tLoss: 0.178901\n",
      "====> Epoch: 71 Average loss: 0.1460\n",
      "====> Validation MSE after Epoch 71: 0.1460\n",
      "Train Epoch: 72 [0/67 (0%)]\tLoss: 0.153510\n",
      "====> Epoch: 72 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 72: 0.1459\n",
      "Train Epoch: 73 [0/67 (0%)]\tLoss: 0.160799\n",
      "====> Epoch: 73 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 73: 0.1459\n",
      "Train Epoch: 74 [0/67 (0%)]\tLoss: 0.156251\n",
      "====> Epoch: 74 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 74: 0.1458\n",
      "Train Epoch: 75 [0/67 (0%)]\tLoss: 0.114178\n",
      "====> Epoch: 75 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 75: 0.1460\n",
      "Train Epoch: 76 [0/67 (0%)]\tLoss: 0.135271\n",
      "====> Epoch: 76 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 76: 0.1457\n",
      "Train Epoch: 77 [0/67 (0%)]\tLoss: 0.133212\n",
      "====> Epoch: 77 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 77: 0.1459\n",
      "Train Epoch: 78 [0/67 (0%)]\tLoss: 0.097625\n",
      "====> Epoch: 78 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 78: 0.1459\n",
      "Train Epoch: 79 [0/67 (0%)]\tLoss: 0.166179\n",
      "====> Epoch: 79 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 79: 0.1458\n",
      "Train Epoch: 80 [0/67 (0%)]\tLoss: 0.145534\n",
      "====> Epoch: 80 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 80: 0.1457\n",
      "Train Epoch: 81 [0/67 (0%)]\tLoss: 0.157829\n",
      "====> Epoch: 81 Average loss: 0.1457\n",
      "====> Validation MSE after Epoch 81: 0.1459\n",
      "Train Epoch: 82 [0/67 (0%)]\tLoss: 0.169801\n",
      "====> Epoch: 82 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 82: 0.1458\n",
      "Train Epoch: 83 [0/67 (0%)]\tLoss: 0.182150\n",
      "====> Epoch: 83 Average loss: 0.1457\n",
      "====> Validation MSE after Epoch 83: 0.1458\n",
      "Train Epoch: 84 [0/67 (0%)]\tLoss: 0.113940\n",
      "====> Epoch: 84 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 84: 0.1457\n",
      "Train Epoch: 85 [0/67 (0%)]\tLoss: 0.157513\n",
      "====> Epoch: 85 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 85: 0.1458\n",
      "Train Epoch: 86 [0/67 (0%)]\tLoss: 0.122749\n",
      "====> Epoch: 86 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 86: 0.1458\n",
      "Train Epoch: 87 [0/67 (0%)]\tLoss: 0.160363\n",
      "====> Epoch: 87 Average loss: 0.1456\n",
      "====> Validation MSE after Epoch 87: 0.1457\n",
      "Train Epoch: 88 [0/67 (0%)]\tLoss: 0.125019\n",
      "====> Epoch: 88 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 88: 0.1460\n",
      "Train Epoch: 89 [0/67 (0%)]\tLoss: 0.212435\n",
      "====> Epoch: 89 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 89: 0.1458\n",
      "Train Epoch: 90 [0/67 (0%)]\tLoss: 0.138329\n",
      "====> Epoch: 90 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 90: 0.1457\n",
      "Train Epoch: 91 [0/67 (0%)]\tLoss: 0.152320\n",
      "====> Epoch: 91 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 91: 0.1459\n",
      "Train Epoch: 92 [0/67 (0%)]\tLoss: 0.137909\n",
      "====> Epoch: 92 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 92: 0.1458\n",
      "Train Epoch: 93 [0/67 (0%)]\tLoss: 0.151816\n",
      "====> Epoch: 93 Average loss: 0.1457\n",
      "====> Validation MSE after Epoch 93: 0.1457\n",
      "Train Epoch: 94 [0/67 (0%)]\tLoss: 0.156337\n",
      "====> Epoch: 94 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 94: 0.1457\n",
      "Train Epoch: 95 [0/67 (0%)]\tLoss: 0.179774\n",
      "====> Epoch: 95 Average loss: 0.1457\n",
      "====> Validation MSE after Epoch 95: 0.1457\n",
      "Train Epoch: 96 [0/67 (0%)]\tLoss: 0.127606\n",
      "====> Epoch: 96 Average loss: 0.1457\n",
      "====> Validation MSE after Epoch 96: 0.1457\n",
      "Train Epoch: 97 [0/67 (0%)]\tLoss: 0.149520\n",
      "====> Epoch: 97 Average loss: 0.1457\n",
      "====> Validation MSE after Epoch 97: 0.1461\n",
      "Train Epoch: 98 [0/67 (0%)]\tLoss: 0.182646\n",
      "====> Epoch: 98 Average loss: 0.1458\n",
      "====> Validation MSE after Epoch 98: 0.1458\n",
      "Train Epoch: 99 [0/67 (0%)]\tLoss: 0.153326\n",
      "====> Epoch: 99 Average loss: 0.1457\n",
      "====> Validation MSE after Epoch 99: 0.1457\n",
      "Train Epoch: 100 [0/67 (0%)]\tLoss: 0.119718\n",
      "====> Epoch: 100 Average loss: 0.1459\n",
      "====> Validation MSE after Epoch 100: 0.1456\n",
      "Training model for group: swedd\n",
      "Train Epoch: 1 [0/14 (0%)]\tLoss: 13.307394\n",
      "====> Epoch: 1 Average loss: 13.3074\n",
      "====> Validation MSE after Epoch 1: 13.0031\n",
      "Train Epoch: 2 [0/14 (0%)]\tLoss: 13.084855\n",
      "====> Epoch: 2 Average loss: 13.0849\n",
      "====> Validation MSE after Epoch 2: 12.7962\n",
      "Train Epoch: 3 [0/14 (0%)]\tLoss: 12.903814\n",
      "====> Epoch: 3 Average loss: 12.9038\n",
      "====> Validation MSE after Epoch 3: 12.6247\n",
      "Train Epoch: 4 [0/14 (0%)]\tLoss: 12.685974\n",
      "====> Epoch: 4 Average loss: 12.6860\n",
      "====> Validation MSE after Epoch 4: 12.4150\n",
      "Train Epoch: 5 [0/14 (0%)]\tLoss: 12.531601\n",
      "====> Epoch: 5 Average loss: 12.5316\n",
      "====> Validation MSE after Epoch 5: 12.2531\n",
      "Train Epoch: 6 [0/14 (0%)]\tLoss: 12.396373\n",
      "====> Epoch: 6 Average loss: 12.3964\n",
      "====> Validation MSE after Epoch 6: 12.0908\n",
      "Train Epoch: 7 [0/14 (0%)]\tLoss: 12.146048\n",
      "====> Epoch: 7 Average loss: 12.1460\n",
      "====> Validation MSE after Epoch 7: 11.9209\n",
      "Train Epoch: 8 [0/14 (0%)]\tLoss: 11.955356\n",
      "====> Epoch: 8 Average loss: 11.9554\n",
      "====> Validation MSE after Epoch 8: 11.7727\n",
      "Train Epoch: 9 [0/14 (0%)]\tLoss: 11.750554\n",
      "====> Epoch: 9 Average loss: 11.7506\n",
      "====> Validation MSE after Epoch 9: 11.5440\n",
      "Train Epoch: 10 [0/14 (0%)]\tLoss: 11.497294\n",
      "====> Epoch: 10 Average loss: 11.4973\n",
      "====> Validation MSE after Epoch 10: 11.3446\n",
      "Train Epoch: 11 [0/14 (0%)]\tLoss: 11.421606\n",
      "====> Epoch: 11 Average loss: 11.4216\n",
      "====> Validation MSE after Epoch 11: 11.1563\n",
      "Train Epoch: 12 [0/14 (0%)]\tLoss: 11.271090\n",
      "====> Epoch: 12 Average loss: 11.2711\n",
      "====> Validation MSE after Epoch 12: 11.0026\n",
      "Train Epoch: 13 [0/14 (0%)]\tLoss: 11.181792\n",
      "====> Epoch: 13 Average loss: 11.1818\n",
      "====> Validation MSE after Epoch 13: 10.7948\n",
      "Train Epoch: 14 [0/14 (0%)]\tLoss: 10.833294\n",
      "====> Epoch: 14 Average loss: 10.8333\n",
      "====> Validation MSE after Epoch 14: 10.6359\n",
      "Train Epoch: 15 [0/14 (0%)]\tLoss: 10.560614\n",
      "====> Epoch: 15 Average loss: 10.5606\n",
      "====> Validation MSE after Epoch 15: 10.4658\n",
      "Train Epoch: 16 [0/14 (0%)]\tLoss: 10.552461\n",
      "====> Epoch: 16 Average loss: 10.5525\n",
      "====> Validation MSE after Epoch 16: 10.2241\n",
      "Train Epoch: 17 [0/14 (0%)]\tLoss: 10.229683\n",
      "====> Epoch: 17 Average loss: 10.2297\n",
      "====> Validation MSE after Epoch 17: 10.0160\n",
      "Train Epoch: 18 [0/14 (0%)]\tLoss: 10.108539\n",
      "====> Epoch: 18 Average loss: 10.1085\n",
      "====> Validation MSE after Epoch 18: 9.8738\n",
      "Train Epoch: 19 [0/14 (0%)]\tLoss: 9.757871\n",
      "====> Epoch: 19 Average loss: 9.7579\n",
      "====> Validation MSE after Epoch 19: 9.6299\n",
      "Train Epoch: 20 [0/14 (0%)]\tLoss: 9.573587\n",
      "====> Epoch: 20 Average loss: 9.5736\n",
      "====> Validation MSE after Epoch 20: 9.5254\n",
      "Train Epoch: 21 [0/14 (0%)]\tLoss: 9.621235\n",
      "====> Epoch: 21 Average loss: 9.6212\n",
      "====> Validation MSE after Epoch 21: 9.1112\n",
      "Train Epoch: 22 [0/14 (0%)]\tLoss: 9.405101\n",
      "====> Epoch: 22 Average loss: 9.4051\n",
      "====> Validation MSE after Epoch 22: 8.9928\n",
      "Train Epoch: 23 [0/14 (0%)]\tLoss: 9.146603\n",
      "====> Epoch: 23 Average loss: 9.1466\n",
      "====> Validation MSE after Epoch 23: 8.8186\n",
      "Train Epoch: 24 [0/14 (0%)]\tLoss: 9.107033\n",
      "====> Epoch: 24 Average loss: 9.1070\n",
      "====> Validation MSE after Epoch 24: 8.6131\n",
      "Train Epoch: 25 [0/14 (0%)]\tLoss: 8.793274\n",
      "====> Epoch: 25 Average loss: 8.7933\n",
      "====> Validation MSE after Epoch 25: 8.3886\n",
      "Train Epoch: 26 [0/14 (0%)]\tLoss: 8.446504\n",
      "====> Epoch: 26 Average loss: 8.4465\n",
      "====> Validation MSE after Epoch 26: 8.3761\n",
      "Train Epoch: 27 [0/14 (0%)]\tLoss: 8.230414\n",
      "====> Epoch: 27 Average loss: 8.2304\n",
      "====> Validation MSE after Epoch 27: 7.9472\n",
      "Train Epoch: 28 [0/14 (0%)]\tLoss: 8.031179\n",
      "====> Epoch: 28 Average loss: 8.0312\n",
      "====> Validation MSE after Epoch 28: 7.7531\n",
      "Train Epoch: 29 [0/14 (0%)]\tLoss: 7.952815\n",
      "====> Epoch: 29 Average loss: 7.9528\n",
      "====> Validation MSE after Epoch 29: 7.4579\n",
      "Train Epoch: 30 [0/14 (0%)]\tLoss: 7.663412\n",
      "====> Epoch: 30 Average loss: 7.6634\n",
      "====> Validation MSE after Epoch 30: 7.4493\n",
      "Train Epoch: 31 [0/14 (0%)]\tLoss: 7.464213\n",
      "====> Epoch: 31 Average loss: 7.4642\n",
      "====> Validation MSE after Epoch 31: 7.2569\n",
      "Train Epoch: 32 [0/14 (0%)]\tLoss: 7.048136\n",
      "====> Epoch: 32 Average loss: 7.0481\n",
      "====> Validation MSE after Epoch 32: 6.9230\n",
      "Train Epoch: 33 [0/14 (0%)]\tLoss: 6.808696\n",
      "====> Epoch: 33 Average loss: 6.8087\n",
      "====> Validation MSE after Epoch 33: 6.5539\n",
      "Train Epoch: 34 [0/14 (0%)]\tLoss: 6.788010\n",
      "====> Epoch: 34 Average loss: 6.7880\n",
      "====> Validation MSE after Epoch 34: 6.5437\n",
      "Train Epoch: 35 [0/14 (0%)]\tLoss: 6.379817\n",
      "====> Epoch: 35 Average loss: 6.3798\n",
      "====> Validation MSE after Epoch 35: 6.3712\n",
      "Train Epoch: 36 [0/14 (0%)]\tLoss: 6.452138\n",
      "====> Epoch: 36 Average loss: 6.4521\n",
      "====> Validation MSE after Epoch 36: 6.2377\n",
      "Train Epoch: 37 [0/14 (0%)]\tLoss: 6.187675\n",
      "====> Epoch: 37 Average loss: 6.1877\n",
      "====> Validation MSE after Epoch 37: 5.7549\n",
      "Train Epoch: 38 [0/14 (0%)]\tLoss: 6.024021\n",
      "====> Epoch: 38 Average loss: 6.0240\n",
      "====> Validation MSE after Epoch 38: 5.6837\n",
      "Train Epoch: 39 [0/14 (0%)]\tLoss: 5.432610\n",
      "====> Epoch: 39 Average loss: 5.4326\n",
      "====> Validation MSE after Epoch 39: 5.2301\n",
      "Train Epoch: 40 [0/14 (0%)]\tLoss: 5.443904\n",
      "====> Epoch: 40 Average loss: 5.4439\n",
      "====> Validation MSE after Epoch 40: 4.8973\n",
      "Train Epoch: 41 [0/14 (0%)]\tLoss: 5.130077\n",
      "====> Epoch: 41 Average loss: 5.1301\n",
      "====> Validation MSE after Epoch 41: 4.7450\n",
      "Train Epoch: 42 [0/14 (0%)]\tLoss: 4.913095\n",
      "====> Epoch: 42 Average loss: 4.9131\n",
      "====> Validation MSE after Epoch 42: 4.9376\n",
      "Train Epoch: 43 [0/14 (0%)]\tLoss: 4.576697\n",
      "====> Epoch: 43 Average loss: 4.5767\n",
      "====> Validation MSE after Epoch 43: 4.4628\n",
      "Train Epoch: 44 [0/14 (0%)]\tLoss: 4.632537\n",
      "====> Epoch: 44 Average loss: 4.6325\n",
      "====> Validation MSE after Epoch 44: 4.4171\n",
      "Train Epoch: 45 [0/14 (0%)]\tLoss: 4.582992\n",
      "====> Epoch: 45 Average loss: 4.5830\n",
      "====> Validation MSE after Epoch 45: 3.8908\n",
      "Train Epoch: 46 [0/14 (0%)]\tLoss: 4.013987\n",
      "====> Epoch: 46 Average loss: 4.0140\n",
      "====> Validation MSE after Epoch 46: 3.9176\n",
      "Train Epoch: 47 [0/14 (0%)]\tLoss: 4.236944\n",
      "====> Epoch: 47 Average loss: 4.2369\n",
      "====> Validation MSE after Epoch 47: 3.5400\n",
      "Train Epoch: 48 [0/14 (0%)]\tLoss: 3.745117\n",
      "====> Epoch: 48 Average loss: 3.7451\n",
      "====> Validation MSE after Epoch 48: 3.3786\n",
      "Train Epoch: 49 [0/14 (0%)]\tLoss: 3.469141\n",
      "====> Epoch: 49 Average loss: 3.4691\n",
      "====> Validation MSE after Epoch 49: 3.3514\n",
      "Train Epoch: 50 [0/14 (0%)]\tLoss: 3.291020\n",
      "====> Epoch: 50 Average loss: 3.2910\n",
      "====> Validation MSE after Epoch 50: 3.0924\n",
      "Train Epoch: 51 [0/14 (0%)]\tLoss: 3.148473\n",
      "====> Epoch: 51 Average loss: 3.1485\n",
      "====> Validation MSE after Epoch 51: 2.9906\n",
      "Train Epoch: 52 [0/14 (0%)]\tLoss: 2.743636\n",
      "====> Epoch: 52 Average loss: 2.7436\n",
      "====> Validation MSE after Epoch 52: 2.6530\n",
      "Train Epoch: 53 [0/14 (0%)]\tLoss: 3.116918\n",
      "====> Epoch: 53 Average loss: 3.1169\n",
      "====> Validation MSE after Epoch 53: 2.5470\n",
      "Train Epoch: 54 [0/14 (0%)]\tLoss: 2.796995\n",
      "====> Epoch: 54 Average loss: 2.7970\n",
      "====> Validation MSE after Epoch 54: 2.5447\n",
      "Train Epoch: 55 [0/14 (0%)]\tLoss: 2.556475\n",
      "====> Epoch: 55 Average loss: 2.5565\n",
      "====> Validation MSE after Epoch 55: 2.3984\n",
      "Train Epoch: 56 [0/14 (0%)]\tLoss: 2.627765\n",
      "====> Epoch: 56 Average loss: 2.6278\n",
      "====> Validation MSE after Epoch 56: 2.1524\n",
      "Train Epoch: 57 [0/14 (0%)]\tLoss: 2.387543\n",
      "====> Epoch: 57 Average loss: 2.3875\n",
      "====> Validation MSE after Epoch 57: 1.8474\n",
      "Train Epoch: 58 [0/14 (0%)]\tLoss: 1.990840\n",
      "====> Epoch: 58 Average loss: 1.9908\n",
      "====> Validation MSE after Epoch 58: 1.9040\n",
      "Train Epoch: 59 [0/14 (0%)]\tLoss: 2.067096\n",
      "====> Epoch: 59 Average loss: 2.0671\n",
      "====> Validation MSE after Epoch 59: 2.0349\n",
      "Train Epoch: 60 [0/14 (0%)]\tLoss: 2.136641\n",
      "====> Epoch: 60 Average loss: 2.1366\n",
      "====> Validation MSE after Epoch 60: 1.7253\n",
      "Train Epoch: 61 [0/14 (0%)]\tLoss: 1.607247\n",
      "====> Epoch: 61 Average loss: 1.6072\n",
      "====> Validation MSE after Epoch 61: 1.4365\n",
      "Train Epoch: 62 [0/14 (0%)]\tLoss: 1.931168\n",
      "====> Epoch: 62 Average loss: 1.9312\n",
      "====> Validation MSE after Epoch 62: 1.5847\n",
      "Train Epoch: 63 [0/14 (0%)]\tLoss: 1.455911\n",
      "====> Epoch: 63 Average loss: 1.4559\n",
      "====> Validation MSE after Epoch 63: 1.4310\n",
      "Train Epoch: 64 [0/14 (0%)]\tLoss: 1.401852\n",
      "====> Epoch: 64 Average loss: 1.4019\n",
      "====> Validation MSE after Epoch 64: 1.2994\n",
      "Train Epoch: 65 [0/14 (0%)]\tLoss: 1.320710\n",
      "====> Epoch: 65 Average loss: 1.3207\n",
      "====> Validation MSE after Epoch 65: 1.1766\n",
      "Train Epoch: 66 [0/14 (0%)]\tLoss: 1.392194\n",
      "====> Epoch: 66 Average loss: 1.3922\n",
      "====> Validation MSE after Epoch 66: 1.1578\n",
      "Train Epoch: 67 [0/14 (0%)]\tLoss: 0.990422\n",
      "====> Epoch: 67 Average loss: 0.9904\n",
      "====> Validation MSE after Epoch 67: 0.8934\n",
      "Train Epoch: 68 [0/14 (0%)]\tLoss: 1.269388\n",
      "====> Epoch: 68 Average loss: 1.2694\n",
      "====> Validation MSE after Epoch 68: 0.9281\n",
      "Train Epoch: 69 [0/14 (0%)]\tLoss: 1.124888\n",
      "====> Epoch: 69 Average loss: 1.1249\n",
      "====> Validation MSE after Epoch 69: 0.9364\n",
      "Train Epoch: 70 [0/14 (0%)]\tLoss: 0.858458\n",
      "====> Epoch: 70 Average loss: 0.8585\n",
      "====> Validation MSE after Epoch 70: 0.8149\n",
      "Train Epoch: 71 [0/14 (0%)]\tLoss: 0.898584\n",
      "====> Epoch: 71 Average loss: 0.8986\n",
      "====> Validation MSE after Epoch 71: 0.7501\n",
      "Train Epoch: 72 [0/14 (0%)]\tLoss: 0.778605\n",
      "====> Epoch: 72 Average loss: 0.7786\n",
      "====> Validation MSE after Epoch 72: 0.7445\n",
      "Train Epoch: 73 [0/14 (0%)]\tLoss: 0.743319\n",
      "====> Epoch: 73 Average loss: 0.7433\n",
      "====> Validation MSE after Epoch 73: 0.6971\n",
      "Train Epoch: 74 [0/14 (0%)]\tLoss: 0.773220\n",
      "====> Epoch: 74 Average loss: 0.7732\n",
      "====> Validation MSE after Epoch 74: 0.6008\n",
      "Train Epoch: 75 [0/14 (0%)]\tLoss: 0.730868\n",
      "====> Epoch: 75 Average loss: 0.7309\n",
      "====> Validation MSE after Epoch 75: 0.5848\n",
      "Train Epoch: 76 [0/14 (0%)]\tLoss: 0.696429\n",
      "====> Epoch: 76 Average loss: 0.6964\n",
      "====> Validation MSE after Epoch 76: 0.6054\n",
      "Train Epoch: 77 [0/14 (0%)]\tLoss: 0.635093\n",
      "====> Epoch: 77 Average loss: 0.6351\n",
      "====> Validation MSE after Epoch 77: 0.4909\n",
      "Train Epoch: 78 [0/14 (0%)]\tLoss: 0.529841\n",
      "====> Epoch: 78 Average loss: 0.5298\n",
      "====> Validation MSE after Epoch 78: 0.4566\n",
      "Train Epoch: 79 [0/14 (0%)]\tLoss: 0.519368\n",
      "====> Epoch: 79 Average loss: 0.5194\n",
      "====> Validation MSE after Epoch 79: 0.4758\n",
      "Train Epoch: 80 [0/14 (0%)]\tLoss: 0.450494\n",
      "====> Epoch: 80 Average loss: 0.4505\n",
      "====> Validation MSE after Epoch 80: 0.3803\n",
      "Train Epoch: 81 [0/14 (0%)]\tLoss: 0.412716\n",
      "====> Epoch: 81 Average loss: 0.4127\n",
      "====> Validation MSE after Epoch 81: 0.3853\n",
      "Train Epoch: 82 [0/14 (0%)]\tLoss: 0.383313\n",
      "====> Epoch: 82 Average loss: 0.3833\n",
      "====> Validation MSE after Epoch 82: 0.3852\n",
      "Train Epoch: 83 [0/14 (0%)]\tLoss: 0.384033\n",
      "====> Epoch: 83 Average loss: 0.3840\n",
      "====> Validation MSE after Epoch 83: 0.3422\n",
      "Train Epoch: 84 [0/14 (0%)]\tLoss: 0.335834\n",
      "====> Epoch: 84 Average loss: 0.3358\n",
      "====> Validation MSE after Epoch 84: 0.3323\n",
      "Train Epoch: 85 [0/14 (0%)]\tLoss: 0.349278\n",
      "====> Epoch: 85 Average loss: 0.3493\n",
      "====> Validation MSE after Epoch 85: 0.3760\n",
      "Train Epoch: 86 [0/14 (0%)]\tLoss: 0.345050\n",
      "====> Epoch: 86 Average loss: 0.3451\n",
      "====> Validation MSE after Epoch 86: 0.2831\n",
      "Train Epoch: 87 [0/14 (0%)]\tLoss: 0.298699\n",
      "====> Epoch: 87 Average loss: 0.2987\n",
      "====> Validation MSE after Epoch 87: 0.3343\n",
      "Train Epoch: 88 [0/14 (0%)]\tLoss: 0.299142\n",
      "====> Epoch: 88 Average loss: 0.2991\n",
      "====> Validation MSE after Epoch 88: 0.2421\n",
      "Train Epoch: 89 [0/14 (0%)]\tLoss: 0.315349\n",
      "====> Epoch: 89 Average loss: 0.3153\n",
      "====> Validation MSE after Epoch 89: 0.2533\n",
      "Train Epoch: 90 [0/14 (0%)]\tLoss: 0.286320\n",
      "====> Epoch: 90 Average loss: 0.2863\n",
      "====> Validation MSE after Epoch 90: 0.2478\n",
      "Train Epoch: 91 [0/14 (0%)]\tLoss: 0.247799\n",
      "====> Epoch: 91 Average loss: 0.2478\n",
      "====> Validation MSE after Epoch 91: 0.2298\n",
      "Train Epoch: 92 [0/14 (0%)]\tLoss: 0.243888\n",
      "====> Epoch: 92 Average loss: 0.2439\n",
      "====> Validation MSE after Epoch 92: 0.2145\n",
      "Train Epoch: 93 [0/14 (0%)]\tLoss: 0.215108\n",
      "====> Epoch: 93 Average loss: 0.2151\n",
      "====> Validation MSE after Epoch 93: 0.2112\n",
      "Train Epoch: 94 [0/14 (0%)]\tLoss: 0.241244\n",
      "====> Epoch: 94 Average loss: 0.2412\n",
      "====> Validation MSE after Epoch 94: 0.1942\n",
      "Train Epoch: 95 [0/14 (0%)]\tLoss: 0.209697\n",
      "====> Epoch: 95 Average loss: 0.2097\n",
      "====> Validation MSE after Epoch 95: 0.1924\n",
      "Train Epoch: 96 [0/14 (0%)]\tLoss: 0.202152\n",
      "====> Epoch: 96 Average loss: 0.2022\n",
      "====> Validation MSE after Epoch 96: 0.2037\n",
      "Train Epoch: 97 [0/14 (0%)]\tLoss: 0.205763\n",
      "====> Epoch: 97 Average loss: 0.2058\n",
      "====> Validation MSE after Epoch 97: 0.1887\n",
      "Train Epoch: 98 [0/14 (0%)]\tLoss: 0.190578\n",
      "====> Epoch: 98 Average loss: 0.1906\n",
      "====> Validation MSE after Epoch 98: 0.1828\n",
      "Train Epoch: 99 [0/14 (0%)]\tLoss: 0.175769\n",
      "====> Epoch: 99 Average loss: 0.1758\n",
      "====> Validation MSE after Epoch 99: 0.1703\n",
      "Train Epoch: 100 [0/14 (0%)]\tLoss: 0.177301\n",
      "====> Epoch: 100 Average loss: 0.1773\n",
      "====> Validation MSE after Epoch 100: 0.1686\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "optimizers = {}\n",
    "for group in ['control', 'patient', 'prodromal', 'swedd']:\n",
    "    models[group] = AsymmetryVAE().to(DEVICE)\n",
    "    optimizers[group] = optim.Adam(models[group].parameters(), lr=1e-4)\n",
    "    dataset = TensorDataset(tensors[group], tensors[group])\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    print(f'Training model for group: {group}')\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        models[group].train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, (data, _) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            optimizers[group].zero_grad()\n",
    "            recon_batch, mu, logvar = models[group](data)\n",
    "            loss = loss_function(recon_batch, data, mu, logvar)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(models[group].parameters(), max_norm=1.0)\n",
    "            train_loss += loss.item()\n",
    "            optimizers[group].step()\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(dataloader.dataset)} ({100. * batch_idx / len(dataloader):.0f}%)]\\tLoss: {loss.item() / len(data):.6f}')\n",
    "        avg_train_loss = train_loss / len(dataloader.dataset)\n",
    "        print(f'====> Epoch: {epoch} Average loss: {avg_train_loss:.4f}')\n",
    "        \n",
    "        # Calculate validation MSE\n",
    "        val_mse = calculate_mse(dataloader, models[group])\n",
    "        print(f'====> Validation MSE after Epoch {epoch}: {val_mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_sample_num = np.min([control_asymm_vectors.shape[0], patient_asymm_vectors.shape[0], prodromal_asymm_vectors.shape[0], swedd_asymm_vectors.shape[0]])\n",
    "data_control = control_asymm_vectors[:least_sample_num]\n",
    "data_patient = patient_asymm_vectors[:least_sample_num]\n",
    "data_prodromal = prodromal_asymm_vectors[:least_sample_num]\n",
    "data_swedd = swedd_asymm_vectors[:least_sample_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_control = np.array([get_latent_space(models['control'], vec) for vec in data_control]).reshape((-1, LATENT_DIM))\n",
    "latent_space_patient = np.array([get_latent_space(models['patient'], vec) for vec in data_patient]).reshape((-1,LATENT_DIM))\n",
    "latent_space_prodromal = np.array([get_latent_space(models['prodromal'], vec) for vec in data_prodromal]).reshape((-1,LATENT_DIM))\n",
    "latent_space_swedd = np.array([get_latent_space(models['swedd'], vec) for vec in data_swedd]).reshape((-1,LATENT_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_1 = data_control\n",
    "input_data_2 = data_patient\n",
    "latent_space_1 = latent_space_control\n",
    "latent_space_2 = latent_space_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonical Correlations on Input: [1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Assuming data_class_1 and data_class_2 are your input datasets\n",
    "cca = CCA(n_components=CCA_COMPONENTS)\n",
    "cca_input_1, cca_input_2 = cca.fit_transform(input_data_1, input_data_2)\n",
    "\n",
    "correlations_input = [np.corrcoef(cca_input_1[:, i], cca_input_2[:, i])[0, 1] for i in range(cca_input_1.shape[1])]\n",
    "print(\"Canonical Correlations on Input:\", correlations_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonical Correlations on Latent Space: [1.0, 0.9999999999999998]\n"
     ]
    }
   ],
   "source": [
    "# Assuming latent_space_class_1 and latent_space_class_2 are obtained from VAEs\n",
    "cca = CCA(n_components=CCA_COMPONENTS)\n",
    "cca_latent_1, cca_latent_2 = cca.fit_transform(latent_space_1, latent_space_2)\n",
    "\n",
    "correlations_latent = [np.corrcoef(cca_latent_1[:, i], cca_latent_2[:, i])[0, 1] for i in range(cca_latent_1.shape[1])]\n",
    "print(\"Canonical Correlations on Latent Space:\", correlations_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(CCA_COMPONENTS):  # Assuming n_components=2\n",
    "    plt.subplot(CCA_COMPONENTS//2, CCA_COMPONENTS, i + 1)\n",
    "    plt.scatter(cca_input_1[:, i], cca_input_2[:, i], label='Input Space')\n",
    "    plt.scatter(cca_latent_1[:, i], cca_latent_2[:, i], label='Latent Space', alpha=0.7)\n",
    "    plt.xlabel(f'Canonical Variable 1, Dim {i+1}')\n",
    "    plt.ylabel(f'Canonical Variable 2, Dim {i+1}')\n",
    "    plt.title(f'Correlations: Input={correlations_input[i]:.2f}, Latent={correlations_latent[i]:.2f}')\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_connectome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
